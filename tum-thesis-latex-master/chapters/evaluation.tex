\chapter{Evaluation}\label{chapter:eval}
In previous chapters, we introduced the design and implementation of 2 prototype
video recommendation applications, MiRec and DiRec, that are developed for the
purpose of testing the effect of distributing the UI of a single user recommender system on the users'
experience; whether this distribution will enrich and facilitate users'
experiences of such systems or would be considered redundant or confusing. To
put this to test, we designed a closed user study, in which participants were
asked to interact with and use both prototype applications, and then give their
feedback evaluation through a user experience survey directly after they are done with
using the apps. In this sections, we explain the different phases of the user
study. We also explain our evaluation method, as well as present the results of
the analysed user experience survey collected from the study participants.

\section{User Study Phases}
The overall goal of the study is to elicit the users’ direct
feedback and impressions of their experience of using the prototype apps.
Each of the phases described below will have its own sub-goal that works
towards this main goal. The study is divided into 3 phases. It starts in a
usability demo in which we demonstrate to participants how to use the apps,
which we thought is necessary to avoid any confusion which might affect the
users rating of the app and tamper with their evaluations. Phase 2 is the actual
user test in which participants interact and use the apps. And the final phase
is the post-experiment user experience survey which is done shortly after phase
2. In the course of 2 weeks, participants were invited to use our apps and give
their feedback. We started our evaluation of the collected user feedback shortly
after we had sufficient number of participants that lead to a stable evaluation.
The following are details of each phase of the study as well as a presentation
of the results and how we interpret them.
\subsection{Phase 1: Usability Demo}
The goal of this phase is to explain clearly to participants the functionalities
of both prototypes. According to the participant’s background, information about
recommender systems, their goal and how they work, were provided. We started by
explaining to participants what tasks are expected to be completed by the them.
We explained that both apps function similarly except that with DiRec, some
functionalities could be done on the phone and others could be transferred to
the screen. We then proceeded with demonstrating to the participant what they
could do with each app. In MiRec, we explained how to play and rated videos, how
to view the video details, and how to navigated through the list of
recommendations in the Home screen as well as through the categories. In DiRec,
we also demoed what could be done on the phone and what could be done on the
screen. The gestures of swipe-left to view details on screen, swipe-right to
filter, and pan on video photo to play on screen were also demoed clearly so
participants would know how to perform the tasks. We explained that the goal of
the study is not to test the functionalities but to get their impression about
the apps. After all fucntionalities were demoed, participants were handed in a
sheet that has the tasks they are expected to complete written down in the form
of steps (see appendix \ref{chapter:appendB}). Also, they were handed in the
user-experience questionnaire sheets. Participants were asked to take their time and ask any questions if needed and to fill-in the questionnaire
directly after they are done.
\begin{figure}[t]
\includegraphics[width=0.75\textwidth, center, center]{figures/IMG_6806}
\caption{Participant's interaction with DiRec during the study.}
\label{fig:figure51}
\end{figure}
\subsection{Phase 2: Prototypes' Functionalities Test}
The user test was done after the participant was made familiar with the apps and
with the tasks of the study. Figures \ref{fig:figure51}, \ref{fig:figure52a},
\ref{fig:figure52b}, \ref{fig:figure52c} shows part of one of the participant's
interaction with DiRec during phase 2 of the user study. Each participant was given an iPhone mobile device with MiRec and DiRec installed, and was asked to sit across of an LD screen, which works as a display to DiRec's LD component.
Participants were asked to start with the app version of their choice to avoid
bias. After they are done with a given version, they start the tasks of the
second version. The tasks were put in place so as to have a standard set of
steps that all participants do. These steps (appendix \ref{chapter:appendB})
mainly consist of:
navigating the list of recommendations through the Home screen, viewing video details, playing
a video, rating a video, selecting a category of choice from the side menu, and
for DiRec, filtering was added to this list. By the end of each set of steps in
each app, we note that optionally users could then proceed interacting with the
apps for whichever scenarios they have in mind. Participants were informed that
this session would on average take between 15 to 20 minutes but they were also
asked to take their time or to stop the experiment at any time if they feel they
are already done and have a feel of the apps already formed. Participants were
observed during this test session, as part of the evaluation is to see how users react to the distribution aspect of the app.
Our observations of participants' interactions constitute part of our evaluation
of the results as shown later in the result section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/IMG_6807}
        \caption{Rating and playing a video.}
        \label{fig:figure52a}
    \end{subfigure}
   
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/IMG_6809}
        \caption{Viewing video details on DiRec}
        \label{fig:figure52b}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/IMG_6810}
        \caption{Filtering videos}
        \label{fig:figure52c}
    \end{subfigure}
   \caption{Interacting with DiRec.}\label{fig:figure52}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\subsection{Phase 3: Post-Experiment Survey}
For eliciting participants' feedback, we use the User Experience Questionnaire
(UEQ) suggested by Laugwitz et al.
\cite{laugwitz2008construction}. This questionnaire is designed to elicit users
direct impression through rating of a set of 26 different attributes of the
apps on a scale from 1 to 7. For the study, each participant was given 2
sheets of the UEQ test and was asked to give their ratings for each app
separately, directly after she/he is done with using the apps. She/He were also
asked to not take more than 3 to 5 minutes in each evaluation, and not to analyse her
answers, as the goal is to get her overall direct impression. Appendix \ref{chapter:appendA}
show all of the 26 aspects that users were to rate. Participants were also asked
to write down their overall feedback and comment in textual form in case they
have any. Some participants preferred to give their feedback directly to us
verbally after the study was complete. We took the change to also interview some
of the participants and ask them about what she/he liked or disliked
specifically about the apps which was valuable to our analysis. Details of our
post-experiment interviews are given in the results section.

\section{Participants Demographics}
24 participants joined our study, non of which are involved directly or
indirectly in this research.
Of the 24 participants, 19 are males and 5 are females. The age range of
participants is between 23 to 31. The majority of the participants are masters
of informatics students at TU Munich, some are researchers or developers in the
same field. We assumed that all participants have no prior knowledge in
recommender systems and explained the procedure similarly to everyone regardless
of their level of expertise.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
\centering
\includegraphics[width=0.7\textwidth]{figures/UEQ-scales}
\caption{User Experience Questionnaire Scale Structure. Source
\cite{UEQHandbook}.}
\label{fig:figure512}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Study Results}
\subsection{The User Experience Questionnaire}
The evaluation of participants' experiences of MiRec and DiRec is done based
on their ratings of the post User Experience Questionnaire (UEQ). The UEQ, as
explained in the UEQ handbook \cite{UEQHandbook}, consists of 6 scales with 26
items, which could be explained as follows:
\begin{itemize}
  \item \textbf{Attractiveness}: measures the overall impression or the
  likability of the product.
  \item \textbf{Perspicuity}: measures learnability and ease-of-use
  (familiarity) with the product
  \item \textbf{Efficiency}: measures the ability to perform tasks without
  exerting extra effort.
  \item \textbf{Dependability}: measures the user's control over the
  product/experience.
  \item \textbf{Stimulation}: measures how exciting and motivating the
  experience is for the user.
  \item \textbf{Novelty}: measures the level of innovation and creativity of the
  product, and the ability of the product to catch the user's interest.
\end{itemize}
These 6 scales are further categorized into 3 groups of qualities:
\textbf{\textit{Attractiveness}}, \textbf{\textit{Pragmatic
Qualities}} (Perspicuity, Efficiency, Dependability), and
\textbf{\textit{Hedonic Qualities}}(Stimulation and Novelty). Figure
\ref{fig:figure512} shows the exact items that participants rated and which
category/scale they fall under.\\
UEQ uses the Alpha Coefficient to measure the consistency of a scale i.e.
all items in a given scale  measure the aspect or quality that is meant to be
measured by this scale.
We need to consider this value in our evaluation since sometimes it is the case
that users could misinterpret a given item, or a given item could be irrelevant
to a study. Therefore, a misinterpreted item in a scale could be detected by
looking at the individual mean value per item. For example, of all items in the
scale have positive values except for a single item that has a negative value,
then it is likely that this item is misinterpreted by participants and should be
evaluated cautiously.\\
The application of the UEQ for measuring the different aspects of users
experience of a given application could be done in 2 ways. If the test involves
comparison of features or experiences of 2 versions fo the same application
(for example a new version of a given product to an older version), one could
use the \textbf{UEQ Compare of Scales Means} method, in which all of the UEQ
scales are compared for the 2 versions to show if one version is significantly different
from the other with respect to each aspect (attractiveness, perspicuity,
efficiency, etc\ldots). In a graphical representation of such comparison,
error bars are shown which indicate a 95\% confidence interval. Confidence
intervals is a measure for the accuracy of the measurements. As explained in
\cite{UEQHandbook}, since scale means would never be the same if the same
experiment was repeated a given number of times, the confidence interval of 95\%
shows where 95\% of the scales means are located. Therefore, if the error bars
(confidence intervals), of the compared products do not overlap at all, this
indicates a significant difference in the 5\% level of the measured scale.\\
The other test could be done on individual products given directly the results
of the means of the different scales. This test could show if a given
application has sufficient user experience i.e. if it meets general
expectations concerning users experience.Scales are measured between -3
(extremely bad) and +3 (extremely good). The test also provides a benchmark of
163 products to classify evaluated applications against. Results put the
evaluated applications as excellent, good, above average, bellow average,
or bad. The UEQ could also be used to make educated guesses about the possible
areas of improvement for a given evaluated application.\\
For the evaluation of our study, we apply both the comparison model between
MiRec and DiRec, as well as individual evaluations for MiRec and DiRec, with a
given comparison with benchmark studies.\\

\subsection{MiRec Results}
In this section we present the results of participants' ratings to MiRec. We
will look at all of the UEQ scales, the consistency of the scales and the rating
given, as well as where MiRec stands in comparison to UEQ's benchmark studies.

\subsubsection{UEQ Scale Means}
UEQ's scales' means for MiRec is given in figure\ref{fig:figure54}. Figure
\ref{fig:figure54a} show the detailed scales, while figure \ref{fig:figure54b}
show the grouped scales. All of the scales show a positive evaluation (above
+0.8). As noticed, attractiveness and pragmatic qualities scores much higher
than hedonic qualities (novelty and stimulation). Nevertheless, all of the scales range in
the yellow and green sections which indicate a positive evaluation.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{figures/mirec-results}
\caption{MiRec Scale Means.}
\label{fig:figure54b}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\includegraphics[width=\textwidth]{figures/mirec-results2}
\caption{MiRec Grouped Scales.}
\label{fig:figure54a}
\end{subfigure}
\caption{MiRec Scale Means.}
\label{fig:figure54}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Quality of Results: Data and Scales Consistency}
Table \ref{table:table55} shows the 5\% confidence intervals of
the scales means. All of the scales means have a relatively small confidence
interval which shows that most of the participants' opinions with respect to
the different scales were consistent, which gives us a strong reason to trust
the results.\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[!htbp]
\tiny
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{7}{|c|}{\textbf{Confidence intervals (p=0.05) per scale}}                            \\ \hline
Scale           & Mean   & Std. Dev. & N  & Confidence & \multicolumn{2}{l|}{Confidence interval} \\ \hline
Attractiveness  & 1.850  & 0.791     & 23 & 0.323      & 1.527               & 2.173              \\ \hline
Perspicuity     & 1.950  & 1.026     & 23 & 0.419      & 1.531               & 2.369              \\ \hline
Efficiency      & 1.675  & 0.624     & 23 & 0.255      & 1.420               & 1.930              \\ \hline
Dependability   & 1.575  & 0.736     & 23 & 0.301      & 1.274               & 1.876              \\ \hline
Stimulation     & 1.225  & 0.854     & 23 & 0.349      & 0.876               & 1.574              \\ \hline
Novelty         & 0.825  & 0.635     & 23 & 0.260      & 0.565               & 1.085              \\ \hline
\end{tabular}
\caption{Confidence Interval MiRec.}
\label{table:table55}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Figure \ref{fig:figure56} shows the means values per item, which is an indicator
to the consistency of how users interpreted the different items in a given
scale. As shown, different items in a given scale are shown in the same color.
Since all items of all scales have positive means, this could indicate that
there were not misinterpreted items in any scale by participants.\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/mirec-results3}
\caption{MiRec Mean Value Per Item.}
\label{fig:figure56}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
UEQ provides a way to detect inconsistent data in a given scale. Since not all
of the participant would give correct or serious ratings, we needed a way to
know if there are any discrepancies in the data. Our results show 2 out of
the 24 participants who gave inconsistent ratings to 3 of the scales. 1
participant gave 2 inconsistent scales ratings, 9 participants gave 1
inconsistent scale ratings. This on average means that the data was sufficiently
consistent.

\subsubsection{Comparison of MiRec to UEQ Benchmark}
Figure \ref{fig:figure57} and table \ref{table:table54} show the results of
comparing MiRec's scales means to UEQ's benchmark. As it is shown, MiRec's
attractiveness measure in the the range of 10\% of best results (excellent).
With respect to dependability, MiRec is better than 75\% of the results, and
worse than 10\% of the results (good). When it comes to stimulation and novelty,
MiRec is better than 50\% of the results, while worse than 25\% of the results
(above average). 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.7\textwidth]{figures/mirec-benchmark}
\caption{MiRec Comparison to Benchmark Studies.}
\label{fig:figure57}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[!htbp]
\tiny
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Scale}          & \textbf{Mean} & \textbf{Comparison to benchmark} & \textbf{Interpretation}                       \\ \hline
\textbf{Attractiveness} & 1.850         & Excellent                         & In the range of the 10\% best results         \\ \hline
\textbf{Perspicuity}    & 1.950         & Excellent                         & In the range of the 10\% best results         \\ \hline
\textbf{Efficiency}     & 1.675         & Excellent                         & In the range of the 10\% best results         \\ \hline
\textbf{Dependability}  & 1.575         & Good                              & 10\% of results better, 75\% of results worse \\ \hline
\textbf{Stimulation}    & 1.225         & Above Average                     & 25\% of results better, 50\% of results worse \\ \hline
\textbf{Novelty}        & 0.825         & Above Average                     & 25\% of results better, 50\% of results worse \\ \hline
\end{tabular}
\caption{MiRec Comparison to Benchmark}
\label{table:table54}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{DiRec Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\centering
\begin{subfigure}[b]{0.5\textwidth}
\includegraphics[width=\textwidth]{figures/direc-results}
\caption{DiRec Scale Means.}
\label{fig:figure16b}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
\includegraphics[width=\textwidth]{figures/direc-results2}
\caption{DiRec Grouped Scale Means.}
\label{fig:figure516a}
\end{subfigure}
\caption{DiRec Scale Means.}
\label{fig:figure516}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
\centering
\includegraphics[width=0.7\textwidth]{figures/direc-results3}
\caption{DiRec Mean Value Per Item.}
\label{fig:figure510}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Confidence Intervals}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{7}{|c|}{\textbf{Confidence intervals (p=0.05) per scale}}                                                                              \\ \hline
\textbf{Scale}          & \textbf{Mean} & \textbf{Std. Dev.} & \textbf{N} & \textbf{Confidence} & \multicolumn{2}{l|}{\textbf{Confidence interval}} \\ \hline
\textbf{Attractiveness} & 1.850         & 0.791              & 23         & 0.323               & 1.527                   & 2.173                   \\ \hline
\textbf{Perspicuity}    & 1.950         & 1.026              & 23         & 0.419               & 1.531                   & 2.369                   \\ \hline
\textbf{Efficiency}     & 1.675         & 0.624              & 23         & 0.255               & 1.420                   & 1.930                   \\ \hline
\textbf{Dependability}  & 1.575         & 0.736              & 23         & 0.301               & 1.274                   & 1.876                   \\ \hline
\textbf{Stimulation}    & 1.225         & 0.854              & 23         & 0.349               & 0.876                   & 1.574                   \\ \hline
\textbf{Novelty}        & 0.825         & 0.635              & 23         & 0.260               & 0.565                   & 1.085                   \\ \hline
\end{tabular}
\caption{DiRec Confidence Intervals.}
\label{table:table57}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Scale Consistency}

\subsubsection{Comparison To Benchmark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
\centering
\includegraphics[width=0.7\textwidth]{figures/direc-benchmark}
\caption{Comparison of DiRec to Benchmark Studies.}
\label{fig:figure511}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Scale}          & \textbf{Mean} & \textbf{Comparison to benchmark} & \textbf{Interpretation}                       \\ \hline
\textbf{Attractiveness} & 1.850         & Excellent                         & In the range of the 10\% best results         \\ \hline
\textbf{Perspicuity}    & 1.950         & Excellent                         & In the range of the 10\% best results         \\ \hline
\textbf{Efficiency}     & 1.675         & Excellent                         & In the range of the 10\% best results         \\ \hline
\textbf{Dependability}  & 1.575         & Good                              & 10\% of results better, 75\% of results worse \\ \hline
\textbf{Stimulation}    & 1.225         & Above Average                     & 25\% of results better, 50\% of results worse \\ \hline
\textbf{Novelty}        & 0.825         & Above Average                     & 25\% of results better, 50\% of results worse \\ \hline
\end{tabular}
\caption{DiRec Comparison to Benchmark Studies.}
\label{table:table56}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Data Inconsistencies}
Explain section\ldots

\subsection{UEQ Compare Scales Means}

\subsubsection{Comparison of Scale Means}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
\centering
\includegraphics[width=0.7\textwidth]{figures/compare}
\caption{Comparison of Scale Means in MiRec and DiRec.}
\label{fig:figure53}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Scale}}} & \multicolumn{6}{c|}{\textbf{MiRec Dataset}}                                                                         \\ \cline{2-7} 
\multicolumn{1}{|c|}{}                                & \textbf{Mean} & \textbf{STD} & \textbf{N} & \textbf{Confidence} & \multicolumn{2}{l|}{\textbf{Confidence Interval}} \\ \hline
\textbf{Attractiveness}                               & 1.34          & 0.91         & 25         & 0.36                & 0.98                     & 1.70                   \\ \hline
\textbf{Perspicuity}                                  & 2.08          & 0.88         & 25         & 0.35                & 1.73                     & 2.43                   \\ \hline
\textbf{Efficiency}                                   & 1.51          & 0.91         & 25         & 0.36                & 1.15                     & 1.87                   \\ \hline
\textbf{Dependability}                                & 1.20          & 0.76         & 25         & 0.30                & 0.90                     & 1.50                   \\ \hline
\textbf{Stimulation}                                  & 0.78          & 0.86         & 25         & 0.34                & 0.44                     & 1.12                   \\ \hline
\textbf{Novelty}                                      & -0.29         & 1.17         & 25         & 0.46                & -0.75                    & 0.17                   \\ \hline
\end{tabular}
\caption{MiRec.}
\label{table:table51}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
\centering  
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Scale}}} & \multicolumn{6}{c|}{\textbf{DiRec Dataset}}                                                                         \\ \cline{2-7} 
\multicolumn{1}{|c|}{}                                & \textbf{Mean} & \textbf{STD} & \textbf{N} & \textbf{Confidence} & \multicolumn{2}{l|}{\textbf{Confidence Interval}} \\ \hline
\textbf{Attractiveness}                               & 1.67          & 1.26         & 23         & 0.52                & 1.15                    & 2.18                    \\ \hline
\textbf{Perspicuity}                                  & 0.98          & 1.59         & 23         & 0.65                & 0.33                    & 1.63                    \\ \hline
\textbf{Efficiency}                                   & 1.32          & 1.26         & 23         & 0.51                & 0.80                    & 1.83                    \\ \hline
\textbf{Dependability}                                & 0.86          & 1.20         & 23         & 0.49                & 0.37                    & 1.35                    \\ \hline
\textbf{Simulation}                                   & 1.66          & 1.03         & 23         & 0.42                & 1.24                    & 2.08                    \\ \hline
\textbf{Novelty}                                      & 1.68          & 0.92         & 23         & 0.38                & 1.31                    & 2.06                    \\ \hline
\end{tabular}
\caption{DiRec.}
\label{table:table52}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{T-Test} 
The T-Test is used to check if the scale means of two measured products differ
significantly. As default the Alpha-Level 0.05 is used.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[]
\centering
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{1}{|r|}{Alpha Level:} & 0.05   &                                                         \\ \hline
                                   &        &                                                         \\ \hline
\textbf{Attractiveness}            & 0.3131 & No Significant Difference       \\ \hline
\textbf{Perspicuity}               & 0.0059 & \textbf{Significant Difference} \\ \hline
\textbf{Efficiency}                & 0.5452 & No Significant Difference       \\ \hline
\textbf{Dependability}             & 0.2509 & No Significant Difference       \\ \hline
\textbf{Stimulation}               & 0.0025 & \textbf{Significant Difference} \\ \hline
\textbf{Novelty}                   & 0.0000 & \textbf{Significant Difference} \\ \hline
\end{tabular}
\caption{T-Test with Alpha Level 0.05.}
\label{table:table53}
\end{table} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Discussion}