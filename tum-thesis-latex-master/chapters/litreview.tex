\chapter{Background and Related Work}\label{chapter:litreview}
In this section we provide the basics and background information in the area of
distributed user interfaces and their applications in different types of
interactive systems, and further on, their attempted application in the area of
recommender systems.
\section{Distributed User Interfaces: Fundamentals, Approaches and Challenges}
\subsection{Fundamentals of DUIs: Definitions, Dimensions and Properties}
\subsubsection{Definitions of DUIs}
Despite of the relative sparsity of applications for DUIs, the literature
includes a number of definitions for what constitutes distributed user interfaces. Some of the provided definitions are synonymous, others are
built on different foundations, which constitutes a problem of ``a consensual
ontology in the domain"\cite{vanderdonckt2010distributed}. In this section, we
collect some of the well known definitions for DUIs and highlight how they
complement each other.\par
Melchior \cite{melchior2011distributed} defines DUIs, in terms of their
different dimensions, as ``any application User Interface (UI) whose components
can be distributed across different displays of different computing platforms that are used by different users, whether they are working at the same place (co-located) or not (remote collaboration).''\par
A synonymous definition is provided by Demeure et al. \cite{demeure20084c},
however, it is provided in the light of the time and space dimensions of DUIs
and introduces the concept of the context-of-use of DUIs.
They define DUIs as ``those interfaces whose different parts can be distributed in time and space on different monitors, screens, and computing platforms, depending on several parameters expressing the context of use, such as the user, the computing platform, and the physical environment in which the user is carrying out her interactive task.'' \par 
Perhaps one of the more comprehensive definitions is given by Vanderdonckt et
al. \cite{vanderdonckt2010distributed} which also continues to draw on the idea of context-of-use. UI distribution
concerns the repartition of one or many elements from one or many user interfaces in order to support one or many users to carry out one or many tasks on one or many domains in one or many contexts of use, each context of use consisting of users, platforms, and environments.\par
Context is defined as s triple of U P and E; user, platform and
environment \cite{vanderdonckt2010distributed}. A single context of
use is when a user is carrying out her task on a dedicated computing platform in
a given environment. By expanding on a single context of use, DUIs are hence
considered  multi-device, multi-monitor, mutli-display,
multi-platform and multi-user. \cite{vanderdonckt2010distributed}\par
From the previously stated definitions, one could draw on characteristics of a
DUI system in terms of what changes they provide for the user's interaction with
and use of the system. Blumendorf et al. \cite{blumendorf2011distributed}
explain that a DUI system enables users to dynamically choose the mode and
devices of interaction based on the current context of use. A user of a DUI
system could also change her choice of devices dynamically and on demand. All
of the user's behaviours are configurable, which should also be storeable and loadable at different times of
use. A DUI system is also by definition multi-modal in the sense that it allows
for the use of different devices simultaneously. And last, a DUI system
should enable a user to share information with other users.\par 
DUIs' definitions are often given in terms of the different platforms,
environments, devices, and users they span, in other words, the dimensions of
distribution. Elmqvist defines distributed user interfaces through the
comprehensive definition: ``A distributed user interface is a user interface whose components are distributed across one
or more of the dimensions input, output, platform, space, and time''
\cite{elmqvist2011distributed}. Thus, it is important to explain what is meant
by these different dimensions of DUIs and to go in details of how the
distribution of such dimensions are possible.

\subsubsection{Dimensions of DUIs}
Several studies draw on the different dimensions of DUIs
\cite{melchior2011distributed}, \cite{demeure20084c},
\cite{elmqvist2011distributed}, \cite{vanderdonckt2010distributed}. According to
these studies, there are several dimensions to user interface distribution:
user, time, space, input, output, platform, task, and element.\par 
Perhaps one of the earliest studies of DUI dimensions was
given by Demeure et al. by describing the 4C model, in
which the distribution dimensions of user interface elements, which alters the
elements' natural habitat (configuration), are given according to the four 'C'
s: computation (what is distributed?), in other words the element of
distribution, which could be the task or the platform, communication (when is it distributed?)
or time, coordination (who initiates distribution?) which is a variation on the
user dimension, and configuration (from where and to where is the distribution operated? on the physical pixel level, or
the logical level)\cite{demeure20084c}. The following is a presentation of the
different dimensions in details, and how they are defined and mentioned in different studies.
\paragraph{Space.}  Both Elmqvist \cite{elmqvist2011distributed} and Melchior
\cite{melchior2011distributed} agree on what defines the space  dimension of
DUIs. This dimension is concerned with whether the user interface is
restricted to the same physical space/ geographic location, or if it could be
distributed geographically. In other words, space defines whether tasks/subtasks
could be carried out in the same location, or distributed over different
locations. 

\paragraph{User.} The user dimension is presented differently in different
studies. Vanderdonckt \cite{vanderdonckt2010distributed} defines it in terms of 
``locus of distribution control''; whether it is in the hands of the user, the
system, or in mixed-initiative way. This idea is originally defined in 4C
model's coordination dimension which is a question of ``who is distributing the interactive system''\cite{demeure20084c}.
In other words, who is responsible for the detection of a need for distribution,
computation of distributed alternatives, selection of a distribution strategy and
finally the execution of this alternative. ``For example, a user may decide
that there is a need to do so and selects various portions of the UI which could
then be migrated to other platforms she is using. When the task is finished, she
may want to recall all migrated portions to restore the initial UI. In this
case, detection, computation, and selection are user-initiated while execution
is system-initiated'' \cite{demeure20084c}. Melchior defines the user dimension
differently. According to \cite{melchior2011distributed}, the user dimension concerns how users interact
with a system: whether the system involves single or multi-users, and whether
the system users could be working competitively or coordinating to perform a
certain task, concurrently or sequentially. Elmqvist, on the other hand, ignores
the user dimension from his definition, claiming that ``In other words, whether or not a DUI is used by a single user or multiple users is not pertinent to our
definition.''\cite{elmqvist2011distributed}

\paragraph{Platforms.} This dimension is concerned with whether the user
interface is executed on a single computing platform, or distributed along
different platforms \cite{elmqvist2011distributed}. What is meant by a
platform is devices with different architectures or operating systems.
Now, the focus is not on a multi device environment, which is an environment
consisting of multiple devices or displays, but rather on how a single interface
could be distributed in such an environment with each of the devices with its
own interaction (input/output) modalities \cite{elmqvist2011distributed}. This
idea is regaining much attention since the number of devices a given user
interacts with in a given environment is increasing and getting smaller in
size.
Vanderdinckt et al. mention that while there has been work done in the areas of
muti-device UIs (UIs produced for several devices simultaneously) and UI
migration(transferring UIs from one device to another while maintaining task
continuity), ``less work has been however devoted towards
dividing a UI across devices, displays, or platforms, where they are used by the
same user or shared by different users \ldots This includes use of
multiple monitors on a same computing platform by a single user, use of
multiple platforms by a single user with synchronisation between, exchange of
information between platforms belonging to different users, moving information
between displays on a single platforms, partition of tasks across displays for a
single user, sharing common information on a common display while keeping some
information private on a own platform" \cite{vanderdonckt2010distributed}.

\paragraph{Input.} Input is considered one of the key aspects in
multi-device scenarios which involves managing interaction with the different
devices with their different input modalities \cite{elmqvist2011distributed}.
One method of handling input in multi-device environments is by using input
redirection ``where the input events from one device are sent to another device
in the environment.''\cite{elmqvist2011distributed}

\paragraph{Output.} The output dimension is concerned with how the system will
present the content to the user, or allow the user to control the content
presentation in a multi-device environment. In other words, will the content be
presented and will always reside on one device, or
redirecting this content from one device/platform to another will be made
possible. This is what is defined as content or display redirection
\cite{elmqvist2011distributed}.

\paragraph{Task.} Many of the studies that tackle the different dimensions of
DUIs discuss the atomic element of UI distribution. For some, the distribution
could be done at the level of UI widgets \cite{vanderdonckt2010distributed}, and
it could even go down to the level of individual pixels \cite{demeure20084c}.
For others however, what defines the basic level of distribution is usually a
task. Lopez et al. \cite{lopez2011formal} defines a task in this context ``as the
set of actions the user performs to accomplish an objective."
Vanderdonckt et al. \cite{vanderdonckt2010distributed} mention that 
to be fully distributed, ``one or many tasks should be considered to be
carried out simultaneously or not in a distributed way.''  Luyten et al.
\cite{luyten2006designing} introduced the notion of situated task in order to model how a task
could be distributed into several sub-tasks to be carried out by one user, but on different platforms in the same environment
over time.

\paragraph{Time.} The time dimension is another crucial aspect of distribution
and also another that is defined differently in different studies. In the 4C
model, it is referred to as the communication aspect of distribution that
answers the question of ``when the distribution happens'' \cite{demeure20084c}.
Demeure et al. explains that a UI distribution is either static or dynamic
depending on when the distribution takes place. If the UI distribution is
static (compile or development time), this means that the distribution is pre-
configured in the system and can not be changed unless the system is
changed/recoded and recompiled. While dynamic UI distribution (run-time) allows
for the change of the UI distribution scheme or strategy at run-time, for
example, on a given user input or behavior, without the need to recode or
recompile the system \cite{demeure20084c}. In dynamic systems,
when the UI requests the loading of a new component, ``the control might select
from a list of UIs with different capabilities of supporting various habitats,
choosing the one that most closely matches the new habitat'' \cite{demeure20084c}.
For example, if a user starts a UI on a mobile device, the system ``might
load a minimal display component to guarantee proper presentation''
\cite{demeure20084c}. A different definition of the time dimension is given by
Melchior as ``some sub-tasks are carried out during different time intervals,
depending on who is contributing to the task" \cite{melchior2011distributed}. While Elmqvist et al.
\cite{elmqvist2011distributed} define time in interactive systems as the
aspect that allows the UI elements to ``execute simultaneously
(synchronously), or distributed in time (asynchronously).''

\subsubsection{Properties of DUIs}
User interfaces of interactive systems hold a number of properties
in order to be considered fully distributed. The following is a set of
some of the DUI properties that were mentioned in different studies.

\paragraph{Portability.}  A UI is said to be portable if ``the UI as a whole or elements of the UI can be transferred between platforms and
devices by means of easy user actions.'' \cite{lopez2011formal}
\paragraph{Decomposability.} A DUI system is said to be decomposable if the set
of elements conforming the UI could be executed independently across different
platforms, while keeping their functionality.\cite{lopez2011formal}
\paragraph{Simultaneity.} This property refers to
the ability of different UI elements of the same DUI system to be managed in
``the same instant of time'' across different platforms.\cite{lopez2011formal}
\paragraph{Continuity.} is the system's ability to maintain
its state while transferring elements of its UI from across different platforms
in the distributed environments.\cite{lopez2011formal}
\paragraph{Consistency.} A DUI system is consistent if it manages all of its
distributed components in the same manner.\cite{lopez2011formal}
\paragraph{Flexibility.} with a flexible DUI system, the
user could perform the same action on different platforms in different
ways.\cite{lopez2011formal}
\paragraph{Multi and Cross.} a DUI system is said to be multi and cross:
device, modal, user and application  \cite{blumendorf2011distributed},
addressing more than one UI element at once on different dimensions, while cross
refers to the dynamic change of elements at run-time.
\paragraph{Usability.} Usability of DUI is an important property to target.
A number of studies are dedicated to how to make DUIs, with the challenge they
present to users, to become more and more usable, easy to learn and to interact
with. Considering the different dimensions of DUIs (i.e.
varying devices, multiple modalities, different users, multiple applications),
it might be difficult for users to keep their mental model of the interactive system up-to-date \cite{blumendorf2011distributed}. The user is challenged by
interacting with a dynamic and widely distributed system of possibly not
obviously related elements that can also change for not immediately obvious
reasons, which requires special consideration for the usability and
intelligibility of DUIs \cite{blumendorf2011distributed}.
\paragraph{Controllability.} denotes the span of control of the user over all
aspects of the distributed UI. Thus, users should be enabled to configure,
reconfigure and save configurations of the system which should statically or
dynamically enable them to tailor the distribution of UI to their needs. One
approach to provide users controlability is through the use of a meta-UI which
is suggest by both the 4C model \cite{demeure20084c} and adopted by Blumendorf
et al. \cite{blumendorf2011distributed}.
\paragraph{Continuous Interaction.} With this aspect, the interaction with the
different components of the distributed systems should be continuous and
undisturbed by the shifts between applications, devices, or displays. Hence the
actual changes should be kept to a minimum so as to provide ``a continuous and consistent
user experience without confusion'' conserving the state of the
interaction \cite{blumendorf2011distributed}.
\paragraph{Configuirability} 
One of the strengths a UI distributed across multiple
devices has over a monolithic system is the ability to flexibly add or remove
computing resources as circumstances dictate. This refers to the dynamic
aspect of a DUI system \cite{chen2011distributed}. Hence, another main challenge
is to allow the dynamic handling, selection and adaptation of different UI variations at runtime by the user of the system. A key factor is the user who is
required to be able to influence this process and override any kind of developer
configuration \cite{blumendorf2011distributed}. This raises the
challenge of uncertain and unknown run-time contexts which should be handled
by the system.
\paragraph{Splittability.} of UI components in a given container of a
distributed UI system is the ability of such components to be presented
separately ``depending on the constraints imposed by the user’s task corresponding to the container''.\cite{demeure20084c}
\paragraph{Migratability.} Migratable user interfaces are defined in
\cite{elmqvist2011distributed} as user interfaces that allow distribution at a
UI component level through migration, such that an abstraction layer redirects parts or the whole of the interface
along the application's hosts. Different techniques are used to achieve
migratability. For instance, one that is similar to what we use in our study is
what is used by Bandelloni and Paterno \cite{bandelloni2004flexible} who use a
migration server to replicate the runtime state and adapt the interface accordingly. Whereas a model based
approach for migrating UIs is taken by Mori et al. \cite{mori2004design}.
Blumendorf et al. \cite{blumendorf2011distributed} refer to complete versus
partial migration/replication, where only part of the UI is involved.
\paragraph{Plasticity.} is the ability of a UI to
adapt to a new interface; specially in a multi-device environment with
different input and output capabilities. Thevenin and Coutaz \cite{thevenin1999plasticity} defined
it as ``the capacity of a UI to withstand variations in both the device and its physical environment while preserving usability.'' In practice, this means that a plastic interface should be able to adapt to different screen sizes (mobile device, laptop, wall-sized display), as well as to different input devices (touch, mouse, voice, gesture, etc).

\subsection{DUIs: Models, Toolkits, Frameworks, and Studies}
While much research tackles problems that are of a DUI nature, few authors take
the conceptual step to generalize these problems into models, frameworks, and
toolkits supporting DUI development \cite{elmqvist2011distributed}. In this
section, we survey some of the studies that aimed at providing DUI models,
design guidelines, frameworks, applications and toolkits, as well as a reference
to some of the existing DUI systems.\par
When it comes to DUI models, an early model was proposed by Demeure et al. in
2005 and then refined in 2008 \cite{demeure20084c} into the 4C model which is
perhaps the most well known and widely
referenced in most studies. The 4C model consists of four basic
components, computation, communication, coordination, and configuration, that
capture the what, when, who, and how aspects of the distribution. 
Melchior et al. \cite{melchior2011distributed} propose a model-based approach that ``capture the abstract operations and requirements necessary for typical DUI systems and toolkits.'' One of the
earliest reference models for DUI is the CAMELEON-RT \cite{coutaz2003software} which is a
middleware software infrastructure for distributed, migratable, and plastic
interfaces \cite{balme2004cameleon}.
Another approach is to combine software engineering methods with DUI models. As
early as 1996, Graham et al. \cite{graham1996efficient} proposed a distributed version of the
model-view-controller (MVC) paradigm. Vandervelpen and Coninx
\cite{vandervelpen2004towards} apply model-based methods to user interface
design, similar to Mori et al. \cite{mori2004design}, but specifically targeted
at heterogeneous device environments. Luyten and Coninx \cite{luyten2006designing} also target
such environments, but take a bottom-up approach focused on designing user
interface elements that support seamless distribution. Finally, the recent
views, instruments, governors, and objects (VIGO) model \cite{klokmose2009vigo} can be used
to build distributed ubiquitous instrumental interaction applications.

Manca et al. \cite{manca2011distributing} describes a model-based approach for
the description of DUIs on top of an extension of the MARIA language. The study
explains that there are 4 levels at which the distribution could occur: elements could be
distributed across multiple devices, elements could be assigned to one given
device, elements could be replicated in multiple devices, or elements could be
adopted by either one device or another.\par
Froberg et al. \cite{froberg2011model} defines the MARVE framework for building
DUI systems. The goal is to provide an approach as similar as possible to
the traditional way of UI components placement, allowing for a smooth
transition from GUI to DUI development. Similarly, presentation modes are defined for
components: atomic presentation refers to when a component can only be
visible on a single device at a time, mirrored refers to when a component is
placed on two or more devices at any given time, and cloned presentations refers
to when a component is placed on two or more devices at any given time, but each
component is unique and not interconnected with the source component.\par
On the other hand, the domain of DUIs is still in
evolution and there exist no toolkit allowing the creation of DUIs.
In most pieces of work, ``there is almost no genuine
DUI" \cite{melchior2011distribution}. Moreover, DUIs toolkits are
considered important for ubiquitous computing, where data and computation is
integrated into everyday objects and
activities \cite{elmqvist2011distributed}. Melchior et al.
\cite{melchior69toolkit} provides a toolkit to support distribution at both
design-time and run-time with very fine and coarse-grained granularity and to
support replicable distribution while being compliant with the DUI goals.
Moreover, a DUI design paradigm defined as The ZOIL design paradigm is given by
Jetter et al. \cite{jetter2012design}.\par
A number of user surveys were conducted in various studies to investigate users'
interaction with DUIs \cite{vanderdonckt2010distributed}. Beale et al.
\cite{beale2007multiple} conducted user surveys to determine the user behavior induced by using a DUI:
they identified the importance of having multiple carets and the complexity of multi-tasking and they suggest design implications for using DUIs in order to support distributed
tasks. In particular, they stressed the importance of a multi-tasking model that
is partially built at the local level of a single user and at the global level
across users when collaboration exists. The global scenario should be also
dissolved into the local scenario in order to preserve the consistency between
common tasks and individual tasks. Tan & Czewinsky \cite{tan2003effects} found
out that physical discontinuities had no effect on performance, but found a
detrimental effect from separating information within the visual field, when
also separated by depth. Due to the multiplicity of interaction techniques in
DUIs, Nacenta et al. conducted a study to compare the efficiency of six
techniques for moving objects from a platform (e.g., a tablet) to another one (e.g., a tabletop) in four different distance ranges and with three movement directions.
Their study suggests that spatial manipulation of data was faster than pressure-based techniques.\par
In the area of social search, Raedle et al. \cite{radle2013twistersearch}
believe that POST-WIMP DUIs could help better support the area of collaborative
social search, and consequently, successfully used DUI design principles to 
develop a prototype, TwitterSearch, which was tested in a user study. Their
results indicated the success of their hypothesis.
On the one hand, several researches have
found DUI techniques useful to adopt into building DUI systems such as IAM
\cite{coutaz2003software}, i-Land \cite{streitz1999land}, Stanford Interactive
Mural \cite{guimbretiere2001fluid}, Aura \cite{sousa2002aura}, ConnecTables
\cite{tandler2001connectables} , Dygimes \cite{vandervelpen2004towards},
DistriXML \cite{grolaux2004migratable}. The ConnecTable is a table-centric
information appliance for seamless coupled/decoupled collaboration
\cite{tandler2001connectables}. iStuff is a physical UI toolkit for UbiComp that
incorporates a wide range of physical components to be used in an interactive
workspace \cite{ballagas2003istuff}. Similarly, the u-Texture \cite{kohtake2005u}
physical panel can be used to effortlessly build smart environments from simple
and easily configurable components. Aura \cite{sousa2002aura} is a software architecture for supporting dynamic variability of computational resources in UbiComp environments.
Similarly, the Gaia \cite{roman2002middleware} middleware infrastructure supports resource
management in physical and interactive computing spaces (called Active Spaces). Additional
frameworks include MediaBroker \cite{modahl2004mediabroker}.\par
Moreover, a number of studies \cite{seifried2011lessons},
\cite{vanderdonckt2010distributed} consider the challenging task developers of
DUIs face and a offer a number of design guidelines, patterns and anti-patterns
that should be considered on designing interfaces for distributed UIs in
multi-device environments.
\subsection{Adopting Dual-Display ``LD/SD'' for UI Distribution}
Dual-Display (shortly LD/SD) is a distribution approach that we adopt in
our study and which was explained and adopted by a similar study by Kaviani et al.
\cite{kaviani2011dual}. Kaviani describes the approach as a promising approach
in interacting with large public displays. The use of ubiquitous cell
phones as an SD component in a DUI not only offer a means to interact with LD
displays, but increasingly offer a small, but high quality screen to complement
the LD. Extending interactive LDs with small devices (SD) such
as PDAs or smart phones has been discussed in earlier research \cite{dix2008public}. The main idea behind this approach, is to execute a user
interface across LD and SD to take advantage of input and output capabilities of
both device types at the same time. Dix and Sas \cite{dix2008public} argue that
such an approach could help designers to solve GUI design issues due to
multi-user interaction with large public displays. 

The goal of Kaviani et al.'s study is similar to ours trying to figure out
the effect of using such approach for UI distribution on users' experiences.
Their primary research question is to verify if users benefit from executing an application across large displays and small devices taking advantage of input
and output capabilities of both devices, i.e. LD and SD. In other words to understand if and how splitting interface entities (user interface widgets) across LD and SD affects user task performance when interacting with applications designed for large public displays.\par
A similar concern to what unfolded during our study was also mentioned in
Kaviani et al.'s study: Which UI components to show on LD and which on SD, and
when to use both. Current research work with large public displays rests on the
assumption that interaction feedback and user requested information (output data) can be presented on LD, SD, or a combination of both. Furthermore, it is assumed that
coupling LD with SD during interaction helps to reduce the load of information
presentation on the LD and increases users’ ability to manage content on large
displays, mainly because of users’ inherent experience in using their phones.
What seems to be missing from the current research work is identifying
differences in design requirements for interactive and non-interactive widgets
depending on whether they are placed on LD or SD. There is lack of clear
guidelines on how users respond to placement of elements in a user interface on
LD or SD. At the UI widget level, they in short sum it up as: To free up real
estate on LD, use SD. For multi-user interaction use LD. A mirrored approach introduces redundancy (which might or might not be useful) and solves neither problem (real estate / interaction).

\subsection{The Use of Gestures for Content Redirection}
For content redirection between SD and LD, we rely mainly on the use of
gestures on UI objects. Allowing the user to perform a simple gesture such as
panning, swiping, scaling, rotating on virtual UI object, instead of having to
follow a menu or dialogue to perform tasks, inherits a POST-WIMP DUIs
approach, where content is considered the interface. Moreover, according to
Woerndl et al. \cite{woerndl2012combining}, the use of gestures is said to
reduce cognitive overhead, hence, facilitates the interaction and performing of
tasks.
\subsection{Challenges and Concerns of DUIs}
Given the above description of what entails building and using
distributed user interfaces, some challenges and concerns are faced
in the course of the development and application of DUIs in interactive systems.
Some of these concerns are mentioned in \cite{melchior2011distributed}: 
\begin{itemize}
\item The lack of specialized tools for the development of 
 DUIs. Hence, on developing DUIs, most of the time is spent on
 devising a method to manage the distribution of the UI in the
 developer's own way. 
\item DUI run-time/dynamic support.
\item Support for multi-user collaboration.
\item 􏰀Execution control in DUI environments.
\item 􏰀Network transparency of DUIs. The distribution of the UIs has to be
network transparent in the sense that the user would not have to manage
network details such as IP addresses etc\ldots.
\item The lack of proper documentation for DUIs.
\end{itemize}

\section{Application of DUIs in Recommender Systems}
Since the focus of our study is the application of DUIs for recommender
systems, after investigating the latest trends in distributed user interfaces,
its tools, best practices, and applications, we turned in our search to the application of DUIs in the field of recommendation applications. To our best knowledge,
surveyed studies for the applications of distributed user interfaces do not
include any which tackle single-user recommendation systems. The application of
DUIs in group recommender systems was investigated in a 2014 study by Woerndl et
al.\cite{worndlvoting}. This study investigates a scenario of a movie
recommender, where UI is distributed on two platforms: a PDA that works as a SD
and a table-top that works as an LD. Users get to view and rate recommended
items on their PDA individually, and as a group, they get to reach a
consensus by doing the voting on the table-top. This DUI solution to the
voting part of group recommendation is proved by the study to improve the
process of reaching consensus among a group. For that, Woerndl et al.'s study
takes a step towards investigating the benefits of using DUIs in recommender
system by showing that the advantages of using DUIs for group consensus during
group recommendation. Our study takes a further step by investigating the
benefits of using DUIs in single-user recommender systems.\par
We are next going to show how we came about designing and implementing our DUI
video recommender solution on top of the described DUI foundations. 
